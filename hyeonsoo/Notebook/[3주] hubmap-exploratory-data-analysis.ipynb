{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HuBMAP - Exploratory Data Analysis\n\nHuBMAP에 대한 데이터 분석: 신장 문제 해결 - [HuBMAP: Hacking the Kidney](https://www.kaggle.com/c/hubmap-kidney-segmentation)\n\n이 해커톤에 사용된 HuBMAP 데이터에는 11개의 frozen frozen 및 9개의 FFPE(Formalin Fixed Paraffin Embedded) PAS 신장 이미지가 포함됩니다. 글로머룰리 FTU 주석이 20개 조직 샘플 모두에 대해 존재합니다. 이 중 일부는 교육을 위해 공유되고 다른 일부는 제출하는 데 사용됩니다."},{"metadata":{},"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-competitions/kaggle/22990/logos/header.png)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:#EAA6D1; border:0' role=\"tab\" aria-controls=\"home\"><center>목차</center></h3>\n\n* [1. 간단한 데이터 탐색](#1)\n* [2. 이미지 및 마스크 시각화](#2)\n* [3. 메타데이터 분석](#3)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"!pip install -q -U pip\n!pip install -q -U seaborn","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:#EAA6D1; border:0; color:white'><center>간단한 데이터 탐색<center><h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport cv2\nimport tifffile","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = \"../input/hubmap-kidney-segmentation/\"\nTRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n\nprint(os.listdir(BASE_PATH))","execution_count":3,"outputs":[{"output_type":"stream","text":"['sample_submission.csv', 'HuBMAP-20-dataset_information.csv', 'train.csv', 'test', 'train']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Train masks (학습 마스크)"},{"metadata":{},"cell_type":"markdown","source":"**train.csv** 에는 각 이미지에 대한 고유 ID와 함께 이미지의 개체에 대한 마스크의 RLE 인코딩 표현이 포함됩니다. RLE 인코딩 방식에 대한 자세한 내용은 evaluation 정보를 참조하세요."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\n    os.path.join(BASE_PATH, \"train.csv\")\n)\ndf_train","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"          id                                           encoding\n0  2f6ecfcdf  296084587 4 296115835 6 296115859 14 296147109...\n1  aaa6a05cc  30989109 59 31007591 64 31026074 68 31044556 7...\n2  cb2d976f4  78144363 5 78179297 15 78214231 25 78249165 35...\n3  0486052bb  101676003 6 101701785 8 101727568 9 101753351 ...\n4  e79de561c  7464094 14 7480273 41 7496453 67 7512632 82 75...\n5  095bf7a1f  113430380 22 113468538 67 113506697 111 113544...\n6  54f2eec69  124601765 36 124632133 109 124662536 147 12469...\n7  1e2425f28  49453112 7 49479881 22 49506657 31 49533433 40...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2f6ecfcdf</td>\n      <td>296084587 4 296115835 6 296115859 14 296147109...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aaa6a05cc</td>\n      <td>30989109 59 31007591 64 31026074 68 31044556 7...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cb2d976f4</td>\n      <td>78144363 5 78179297 15 78214231 25 78249165 35...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0486052bb</td>\n      <td>101676003 6 101701785 8 101727568 9 101753351 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e79de561c</td>\n      <td>7464094 14 7480273 41 7496453 67 7512632 82 75...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>095bf7a1f</td>\n      <td>113430380 22 113468538 67 113506697 111 113544...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>54f2eec69</td>\n      <td>124601765 36 124632133 109 124662536 147 12469...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1e2425f28</td>\n      <td>49453112 7 49479881 22 49506657 31 49533433 40...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Submission df"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.read_csv(\n    os.path.join(BASE_PATH, \"sample_submission.csv\"))\ndf_sub","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"          id  predicted\n0  b9a3865fc        NaN\n1  b2dc8411c        NaN\n2  26dc41664        NaN\n3  c68fe75ea        NaN\n4  afa5e8098        NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b9a3865fc</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b2dc8411c</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26dc41664</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c68fe75ea</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>afa5e8098</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Number of samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of train images: {df_train.shape[0]}\")\nprint(f\"Number of test images: {df_sub.shape[0]}\")","execution_count":6,"outputs":[{"output_type":"stream","text":"Number of train images: 8\nNumber of test images: 5\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Train and test metadata"},{"metadata":{},"cell_type":"markdown","source":"**HuBMAP-20-dataset_information.csv** 에는 각 이미지에 대한 추가 정보(익명 환자 데이터를 포함)가 있습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info = pd.read_csv(\n    os.path.join(BASE_PATH, \"HuBMAP-20-dataset_information.csv\")\n)\ndf_info.sample(3)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"        image_file  width_pixels  height_pixels  \\\n8   b9a3865fc.tiff         40429          31295   \n11  0486052bb.tiff         34937          25784   \n4   c68fe75ea.tiff         19780          26840   \n\n   anatomical_structures_segmention_file glomerulus_segmentation_file  \\\n8    b9a3865fc-anatomical-structure.json               b9a3865fc.json   \n11   0486052bb-anatomical-structure.json               0486052bb.json   \n4    c68fe75ea-anatomical-structure.json               c68fe75ea.json   \n\n    patient_number   race               ethnicity     sex  age  \\\n8            67347  White  Not Hispanic or Latino  Female   58   \n11           67177  White  Not Hispanic or Latino    Male   31   \n4            67112  White  Not Hispanic or Latino    Male   56   \n\n    weight_kilograms  height_centimeters  bmi_kg/m^2 laterality  \\\n8               59.0               160.0        23.0      Right   \n11             106.1               180.3        32.6      Right   \n4               91.2               167.6        32.5       Left   \n\n    percent_cortex  percent_medulla  \n8               55               45  \n11              80               20  \n4               80               20  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_file</th>\n      <th>width_pixels</th>\n      <th>height_pixels</th>\n      <th>anatomical_structures_segmention_file</th>\n      <th>glomerulus_segmentation_file</th>\n      <th>patient_number</th>\n      <th>race</th>\n      <th>ethnicity</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>weight_kilograms</th>\n      <th>height_centimeters</th>\n      <th>bmi_kg/m^2</th>\n      <th>laterality</th>\n      <th>percent_cortex</th>\n      <th>percent_medulla</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>b9a3865fc.tiff</td>\n      <td>40429</td>\n      <td>31295</td>\n      <td>b9a3865fc-anatomical-structure.json</td>\n      <td>b9a3865fc.json</td>\n      <td>67347</td>\n      <td>White</td>\n      <td>Not Hispanic or Latino</td>\n      <td>Female</td>\n      <td>58</td>\n      <td>59.0</td>\n      <td>160.0</td>\n      <td>23.0</td>\n      <td>Right</td>\n      <td>55</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0486052bb.tiff</td>\n      <td>34937</td>\n      <td>25784</td>\n      <td>0486052bb-anatomical-structure.json</td>\n      <td>0486052bb.json</td>\n      <td>67177</td>\n      <td>White</td>\n      <td>Not Hispanic or Latino</td>\n      <td>Male</td>\n      <td>31</td>\n      <td>106.1</td>\n      <td>180.3</td>\n      <td>32.6</td>\n      <td>Right</td>\n      <td>80</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c68fe75ea.tiff</td>\n      <td>19780</td>\n      <td>26840</td>\n      <td>c68fe75ea-anatomical-structure.json</td>\n      <td>c68fe75ea.json</td>\n      <td>67112</td>\n      <td>White</td>\n      <td>Not Hispanic or Latino</td>\n      <td>Male</td>\n      <td>56</td>\n      <td>91.2</td>\n      <td>167.6</td>\n      <td>32.5</td>\n      <td>Left</td>\n      <td>80</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Utility functions"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n# RLE 인코딩을 Mask 이미지로 변환\ndef rle2mask(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [\n        np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])\n    ]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape).T\n\n\n# 이미지 및 마스크 불러오기\ndef read_image(image_id, scale=None, verbose=1):\n    image = tifffile.imread(\n        os.path.join(BASE_PATH, f\"train/{image_id}.tiff\")\n    )\n    if len(image.shape) == 5:\n        image = image.squeeze().transpose(1, 2, 0)\n    \n    mask = rle2mask(\n        df_train[df_train[\"id\"] == image_id][\"encoding\"].values[0], \n        (image.shape[1], image.shape[0])\n    )\n    \n    if verbose:\n        print(f\"[{image_id}] Image shape: {image.shape}\")\n        print(f\"[{image_id}] Mask shape: {mask.shape}\")\n    \n    if scale:\n        new_size = (image.shape[1] // scale, image.shape[0] // scale)\n        image = cv2.resize(image, new_size)\n        mask = cv2.resize(mask, new_size)\n        \n        if verbose:\n            print(f\"[{image_id}] Resized Image shape: {image.shape}\")\n            print(f\"[{image_id}] Resized Mask shape: {mask.shape}\")\n        \n    return image, mask\n\n\n# 테스트 이미지 불러오기 (마스크 제외)\ndef read_test_image(image_id, scale=None, verbose=1):\n    image = tifffile.imread(\n        os.path.join(BASE_PATH, f\"test/{image_id}.tiff\")\n    )\n    if len(image.shape) == 5:\n        image = image.squeeze().transpose(1, 2, 0)\n    \n    if verbose:\n        print(f\"[{image_id}] Image shape: {image.shape}\")\n    \n    if scale:\n        new_size = (image.shape[1] // scale, image.shape[0] // scale)\n        image = cv2.resize(image, new_size)\n        \n        if verbose:\n            print(f\"[{image_id}] Resized Image shape: {image.shape}\")\n        \n    return image\n\n\n# 이미지 및 마스크 시각화\ndef plot_image_and_mask(image, mask, image_id):\n    plt.figure(figsize=(16, 10))\n    \n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title(f\"Image {image_id}\", fontsize=18)\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(image)\n    plt.imshow(mask, cmap=\"hot\", alpha=0.5)\n    plt.title(f\"Image {image_id} + mask\", fontsize=18)    \n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(mask, cmap=\"hot\")\n    plt.title(f\"Mask\", fontsize=18)    \n    \n    plt.show()\n    \n\n# 이미지 및 마스크 정사각형으로 불러오기 \ndef plot_grid_image_with_mask(image, mask):\n    plt.figure(figsize=(16, 16))\n    \n    w_len = image.shape[0]\n    h_len = image.shape[1]\n    \n    min_len = min(w_len, h_len)\n    w_start = (w_len - min_len) // 2\n    h_start = (h_len - min_len) // 2\n    \n    plt.imshow(image[w_start : w_start + min_len, h_start : h_start + min_len])\n    plt.imshow(\n        mask[w_start : w_start + min_len, h_start : h_start + min_len], cmap=\"hot\", alpha=0.5,\n    )\n    plt.axis(\"off\")\n            \n    plt.show()\n    \n\n# Whole Slide 이미지에서 패치만 불러오기\ndef plot_slice_image_and_mask(image, mask, start_h, end_h, start_w, end_w):\n    plt.figure(figsize=(16, 5))\n    \n    sub_image = image[start_h:end_h, start_w:end_w, :]\n    sub_mask = mask[start_h:end_h, start_w:end_w]\n    \n    plt.subplot(1, 3, 1)\n    plt.imshow(sub_image)\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(sub_image)\n    plt.imshow(sub_mask, cmap=\"hot\", alpha=0.5)\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(sub_mask, cmap=\"hot\")\n    plt.axis(\"off\")\n    \n    plt.show()","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:#EAA6D1; border:0; color:white'><center>이미지 및 마스크 시각화<center><h2>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"small_ids = [\n    \"0486052bb\", \"095bf7a1f\", \"1e2425f28\", \"2f6ecfcdf\",\n    \"54f2eec69\", \"aaa6a05cc\", \"cb2d976f4\", \"e79de561c\",\n]\nsmall_images = []\nsmall_masks = []\n\nfor small_id in small_ids:\n    tmp_image, tmp_mask = read_image(small_id, scale=20, verbose=0)\n    small_images.append(tmp_image)\n    small_masks.append(tmp_mask)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train images"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 16))\nfor ind, (tmp_id, tmp_image) in enumerate(zip(small_ids, small_images)):\n    plt.subplot(3, 3, ind + 1)\n    plt.imshow(tmp_image)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train images + masks"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 16))\nfor ind, (tmp_id, tmp_image, tmp_mask) in enumerate(zip(small_ids, small_images, small_masks)):\n    plt.subplot(3, 3, ind + 1)\n    plt.imshow(tmp_image)\n    plt.imshow(tmp_mask, cmap=\"hot\", alpha=0.5)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"small_ids = [\n    \"26dc41664\", \"afa5e8098\", \"b2dc8411c\", \"b9a3865fc\", \"c68fe75ea\",\n]\nsmall_images = []\n\nfor small_id in small_ids:\n    tmp_image = read_test_image(small_id, scale=20, verbose=0)\n    small_images.append(tmp_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test images"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 11))\nfor ind, (tmp_id, tmp_image) in enumerate(zip(small_ids, small_images)):\n    plt.subplot(2, 3, ind + 1)\n    plt.imshow(tmp_image)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 0486052bb"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_id = \"0486052bb\"\nimage, mask = read_image(image_id, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_image_and_mask(image, mask, image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_slice_image_and_mask(image, mask, 5000, 7500, 2500, 5000)\nplot_slice_image_and_mask(image, mask, 5250, 5720, 3500, 4000)\nplot_slice_image_and_mask(image, mask, 5375, 5575, 3650, 3850)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_grid_image_with_mask(image, mask)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 095bf7a1f"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_id = \"095bf7a1f\"\nimage, mask = read_image(image_id, scale=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_image_and_mask(image, mask, image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_slice_image_and_mask(image, mask, 7500, 10000, 10000, 12500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_grid_image_with_mask(image, mask)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1e2425f28"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_id = \"1e2425f28\"\nimage, mask = read_image(image_id, scale=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_image_and_mask(image, mask, image_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2f6ecfcdf"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_id = \"2f6ecfcdf\"\nimage, mask = read_image(image_id, scale=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_image_and_mask(image, mask, image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_slice_image_and_mask(image, mask, 10000, 12000, 8000, 10000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## aaa6a05cc"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_id = \"aaa6a05cc\"\nimage, mask = read_image(image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_image_and_mask(image, mask, image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_slice_image_and_mask(image, mask, 6500, 8500, 7000, 9000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## e79de561c"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_id = \"e79de561c\"\nimage, mask = read_image(image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_image_and_mask(image, mask, image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_slice_image_and_mask(image, mask, 4000, 6000, 2000, 4000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:#EAA6D1; border:0; color:white'><center>Metadata Analysis<center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_json(\n    os.path.join(BASE_PATH, \"train/0486052bb-anatomical-structure.json\")\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_json(\n    os.path.join(BASE_PATH, \"train/0486052bb.json\")\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info[\"split\"] = \"test\"\ndf_info.loc[df_info[\"image_file\"].isin(os.listdir(os.path.join(BASE_PATH, \"train\"))), \"split\"] = \"train\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info[\"area\"] = df_info[\"width_pixels\"] * df_info[\"height_pixels\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 35))\nplt.subplot(6, 2, 1)\nsn.countplot(x=\"race\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 2)\nsn.countplot(x=\"ethnicity\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 3)\nsn.countplot(x=\"sex\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 4)\nsn.countplot(x=\"laterality\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 5)\nsn.histplot(x=\"age\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 6)\nsn.histplot(x=\"weight_kilograms\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 7)\nsn.histplot(x=\"height_centimeters\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 8)\nsn.histplot(x=\"bmi_kg/m^2\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 9)\nsn.histplot(x=\"percent_cortex\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 10)\nsn.histplot(x=\"percent_medulla\", hue=\"split\", data=df_info)\nplt.subplot(6, 2, 11)\nsn.histplot(x=\"area\", hue=\"split\", data=df_info);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WORK IN PROGRESS..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}